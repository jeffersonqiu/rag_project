{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from operator import itemgetter\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LLM Powered Autonomous Agents refers to autonomous agent systems where a large language model (LLM) serves as the core controller or brain of the agent. These agents are designed to break down complex tasks into smaller subgoals, reflect on past actions, and use natural language interfaces to interact with external components such as memory and tools. However, the reliability of model outputs from LLMs in these systems can be questionable, as they may make formatting errors or exhibit rebellious behavior. The potential of LLM in autonomous agents goes beyond generating text or code, as it can be a powerful problem solver.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Load the Information\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "# 2a. Split the documents into smaller chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, \n",
    "                                               chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# 2b. Select embedding strategy/ type\n",
    "openai_embedding = OpenAIEmbeddings()\n",
    "\n",
    "# 2c. Create the vectorstore\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=openai_embedding)\n",
    "\n",
    "# 3. Create the retriever\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# Define the prompt (not unique to RAG)\n",
    "prompt = \"\"\"Based on the data provided to you here: {context}. \n",
    "Please answer this question: {question}\"\"\"\n",
    "\n",
    "custom_prompt = PromptTemplate.from_template(prompt)\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# Define the chain (not unique to RAG)\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | custom_prompt\n",
    "    | ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "rag_chain.invoke('What is LLM Powered Autonomous Agents')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
